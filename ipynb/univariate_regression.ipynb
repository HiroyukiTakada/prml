{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TNrUFuuP0gmv"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bbHBDDmE0gmy"
   },
   "source": [
    "Univariate regression\n",
    "=================\n",
    "Fit a line or a polynome of specified degree to a 1d dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UoRFQUlLokm4"
   },
   "source": [
    "Make training data\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_nCKZV9u0gmz"
   },
   "outputs": [],
   "source": [
    "# Example 1: define manually\n",
    "import numpy as np\n",
    "x = np.array([5., 3., 0., 4.])\n",
    "y = np.array([4., 4., 1., 3.])\n",
    "x_test = np.array([1.0,  2., 2.5, 4.])\n",
    "y_test = np.array([1.5, 2., 3.5, 4.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HIJqBgJ2pPyZ"
   },
   "outputs": [],
   "source": [
    "# Example 2: the diabetes dataset\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "diabetes.target /= diabetes.target.max()\n",
    "\n",
    "# Use only one feature\n",
    "x = diabetes.data[-20:, np.newaxis, 2].ravel()\n",
    "y = diabetes.target[-20:]\n",
    "x_test = diabetes.data[:-20, np.newaxis, 2].ravel()\n",
    "y_test = diabetes.target[:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZvxP6Rlniu6J"
   },
   "outputs": [],
   "source": [
    "# Example 3: artificial dataset\n",
    "# http://www.scipy-lectures.org/packages/scikit-learn/auto_examples/plot_bias_variance.html#bias-and-variance-of-polynomial-fit\n",
    "import numpy as np\n",
    "generating_func = lambda x, err=0.5: np.random.normal(10 - 1. / (x + 0.1), err)\n",
    "n_samples = 20\n",
    "np.random.seed(0)\n",
    "x = 10 ** np.linspace(-2, 0, n_samples)\n",
    "y = generating_func(x)\n",
    "x_test = np.linspace(-0.2, 1.2, 100)\n",
    "y_test = generating_func(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S3Ah1akFow7B"
   },
   "source": [
    "plot the training points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "R1SAIZS7BCqa"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(3, 3.5))\n",
    "ax = plt.axes()\n",
    "ax.scatter(x_test, y_test, marker='o', c='0.75', s=20)\n",
    "ax.scatter(x, y, marker='x', c='b', s=50)\n",
    "xmin, xmax, dx = x.min(), x.max(), (x.max()-x.min())*0.2\n",
    "ymin, ymax, dy = y.min(), y.max(), (y.max()-y.min())*0.2\n",
    "ax.set_xlim(xmin-dx, xmax+dx)\n",
    "ax.set_ylim(ymin-dy, ymax+dy)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4UTrkDQEu_EU"
   },
   "source": [
    "Compute the model parameters\n",
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "plfSF04aeFWL"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "degree = 1\n",
    "X = PolynomialFeatures(degree).fit_transform(x[:, np.newaxis])\n",
    "if degree < 4:\n",
    "    print(\"X =\");    print(X)\n",
    "    print(\"X.T.dot(X) =\");    print(X.T.dot(X))\n",
    "w = np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y))\n",
    "print(\"w = X.T.dot(X)).dot(X.T.dot(y) =\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tgg8IB2whMHQ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3.5))\n",
    "ax = plt.axes()\n",
    "x_regr = np.linspace(xmin-dx, xmax+dx, 100)\n",
    "X_regr = PolynomialFeatures(degree).fit_transform(x_regr[:, np.newaxis])\n",
    "y_regr = X_regr.dot(w)\n",
    "ax.plot(x_regr, y_regr, 'b-')\n",
    "ax.scatter(x_test, y_test, marker='o', c='0.75', s=20)\n",
    "ax.scatter(x, y, marker='x', c='b', s=50)\n",
    "ax.set_xlim(xmin-dx, xmax+dx)\n",
    "ax.set_ylim(ymin-dy, ymax+dy)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('univariate_regression.png', transparent=True,dpi=300)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"l2 loss (residual) = %.2f\" % mean_squared_error(y, X.dot(w)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fPbdEvDtw_74"
   },
   "source": [
    "Validation of degrees\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eRPDDkcju5VS"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3.5))\n",
    "ax = plt.axes()\n",
    "ax.scatter(x_test, y_test, marker='o', c='0.75', s=20)\n",
    "\n",
    "dmax = min(len(y), 16)\n",
    "residual = np.zeros(dmax)\n",
    "mse_test = np.zeros(dmax)\n",
    "for degree in range(dmax):\n",
    "    # regression\n",
    "    X = PolynomialFeatures(degree).fit_transform(x[:, np.newaxis])\n",
    "    w = np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y))\n",
    "\n",
    "    # compute the mean residual of training data and the mean square error of test data\n",
    "    residual[degree] = mean_squared_error(y, X.dot(w))\n",
    "    X_test = PolynomialFeatures(degree).fit_transform(x_test[:, np.newaxis])\n",
    "    mse_test[degree] = mean_squared_error(y_test, X_test.dot(w))\n",
    "\n",
    "    # plot the regression curve\n",
    "    if degree in [1, 2, 3, 5, 7, 11]:\n",
    "        x_regr = np.linspace(xmin-dx, xmax+dx, 100)\n",
    "        X_regr = PolynomialFeatures(degree).fit_transform(x_regr[:, np.newaxis])\n",
    "        y_regr = X_regr.dot(w)\n",
    "        alpha = min(1, 2**mse_test[0]/mse_test[degree])\n",
    "        val = min(1, 2**residual[degree]/residual[0])\n",
    "        ax.plot(x_regr, y_regr,  lw=1, color =[1-val,1-val,1], alpha=alpha)\n",
    "\n",
    "ax.scatter(x, y, marker='x', c='b', s=50)\n",
    "ax.set_xlim(xmin-dx, xmax+dx)\n",
    "ax.set_ylim(ymin-dy, ymax+dy)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('polynomial_regression.png', transparent=True,dpi=300)\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.axes()\n",
    "if mse_test.max() - mse_test.min() < 1e+2:\n",
    "    ax.plot(range(dmax), residual, 'bs--', label='Train')\n",
    "    ax.plot(range(dmax), mse_test, 'ko--', label='Test')\n",
    "else:\n",
    "    ax.semilogy(range(dmax), residual, 'bs--', label='Train')\n",
    "    ax.semilogy(range(dmax), mse_test, 'ko--', label='Test')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('Degree', fontsize=20)\n",
    "plt.ylabel('$\\\\ell_2$ loss (residual)', fontsize=20)\n",
    "plt.legend(loc=\"upper right\", fontsize=16, frameon=True)\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "ax.set_xlim(-0.1,dmax-0.9)\n",
    "plt.tight_layout()\n",
    "plt.savefig('univariate_regression_loss_vs_degree.png', transparent=True,dpi=300)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "univariate_regression.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
