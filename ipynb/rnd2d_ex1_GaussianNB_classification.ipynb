{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"rnd2d_ex1_GaussianNB_classification.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[{"file_id":"16Glb7Gq8kYxLA3b1TC6M2693YNV6acTF","timestamp":1524836662602}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"2Xf5xoadG9Z0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["%matplotlib inline\n","from __future__ import print_function"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UW1hl94VG9Z8","colab_type":"text"},"cell_type":"markdown","source":["Classification by Gaussian Naive Bayes of 2D data set\n","==================="]},{"metadata":{"id":"PCg8jJ2AG9aH","colab_type":"text"},"cell_type":"markdown","source":["Define functions\n","-------------------\n","You don't have to care about this cell."]},{"metadata":{"id":"QgHEfe14h1eb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","# Independent bivariate normal joint density\n","def N2d(x, mu, variance):\n","    return np.exp(-0.5 * (x[:,0] - mu[0])**2 / variance[0])  *  np.exp(-0.5 * (x[:,1] - mu[1])**2 / variance[1])  /  (2. * np.pi * np.sqrt(variance[0]*variance[1]))\n","\n","from matplotlib import pyplot as plt\n","# Visualization of the estimated distributions\n","def plot2d_GaussianNB(model, X_train, y_train, X_test=None, y_test=None, cmap=None, xlim=None, ylim=None, dxlim=0.5, dylim=0.5, levels=None, linestyles=None, markers=None, colors=None):\n","\n","    plt.figure()\n","    ax = plt.axes()\n","\n","    if xlim is None:\n","        xlim = [X_train[:, 0].min() - dxlim, X_train[:, 0].max() + dxlim]\n","    if ylim is None:\n","        ylim = [X_train[:, 1].min() - dylim, X_train[:, 1].max() + dylim]\n","\n","    xg, yg = np.arange(xlim[0], xlim[1], (xlim[1]-xlim[0])/300.), np.arange(ylim[0], ylim[1], (ylim[1]-ylim[0])/300.)\n","    xx, yy = np.meshgrid(xg, yg)    \n","\n","    if cmap is None:\n","        cmap = ['Blues', 'Reds', 'Greens', 'BuPu', 'RdPu', 'YlGn']\n","    if markers is None:\n","        markers = ['o', 's', '^', '*', '+', 'x']\n","    if colors is None:\n","        colors = ['b', 'r', 'g', 'c', 'm', 'y']\n","    ncmap, nm, nc = len(cmap), len(markers), len(colors)\n","\n","    ncls = len(model.class_count_)\n","    for k in range(ncls):\n","        vmax = 1.  / (2. * np.pi * np.sqrt(model.sigma_[:,0]*model.sigma_[:,1]))\n","    for k in range(ncls):\n","        #mean and variance of each feature per class\n","        mu = model.theta_[k,:]\n","        variance = model.sigma_[k,:]\n","        Z = N2d(np.c_[xx.ravel(),yy.ravel()], mu, variance)\n","\n","        # Put the result into a color plot\n","        #ax.pcolor(xx, yy, Z, cmap=cmap[k], alpha=0.5, edgecolors=None)\n","        Zm = np.ma.masked_array(Z, Z < 0.03*vmax[k])\n","        ax.pcolorfast(xg, yg, Zm.reshape(xx.shape), cmap=cmap[k%ncmap], alpha=0.5)\n","        if levels is not None:\n","            ax.contour(xx, yy, Z.reshape(xx.shape), levels=levels, colors='k', linestyles=linestyles, alpha=0.2)\n","        else:\n","            levels = np.arange(0, vmax[k], vmax[k]/8.)\n","            ax.contour(xx, yy, Z.reshape(xx.shape), levels=levels, colors='k', linestyles=linestyles, alpha=0.2)\n","\n","    if ncls == 2:\n","        decision_function = lambda X: np.log(np.array(model.predict_proba(X)[:,1])/np.array(model.predict_proba(X)[:,0]))\n","        Z = decision_function(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n","        ax.contour(xx, yy, Z.reshape(xx.shape), levels=[0.], colors='k', linestyles=['--'], alpha=1)\n","\n","    # Plot also the training points\n","    y = np.unique(y_train)\n","    for k in range(ncls):\n","        ax.scatter(X_train[y_train==y[k], 0], X_train[y_train==y[k], 1], c=colors[k%nc],  marker=markers[k%nm], cmap=cmap[k%ncmap], edgecolors='k', label='Training data', alpha=1)\n","    # and testing points if given\n","    if X_test is not None and y_test is not None:\n","        y = np.unique(y_train)\n","        for k in range(ncls):\n","            ax.scatter(X_test[y_test==y[k], 0], X_test[y_test==y[k], 1], c=colors[k],  marker=markers[k], cmap=cmap[k], edgecolors='k', label='Test data', alpha=1)\n","        plt.legend(loc=\"upper right\", fontsize=16, frameon=True)\n","        ax.get_legend().legendHandles[0].set_color('k')\n","        ax.get_legend().legendHandles[1].set_color('k')\n","\n","    ax.set_xlim(xx.min(), xx.max())\n","    ax.set_ylim(yy.min(), yy.max())\n","    plt.axis('tight')\n","    plt.xlabel('x1', fontsize=16)\n","    plt.ylabel('x2', fontsize=16)\n","    plt.xticks(fontsize=16)\n","    plt.yticks(fontsize=16)\n","    plt.gca().set_aspect('equal')\n","    plt.tight_layout()\n","    plt.savefig('rnd2d_ex1_GNB.png', transparent=True,dpi=300)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"obFLzXN6G9Z_","colab_type":"text"},"cell_type":"markdown","source":["Make training data\n","------------------"]},{"metadata":{"id":"aQWiGCU0G9aA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Example 1': define manually\n","X = np.array([[22, 1], [13,2], [19,5], [15,8], [11,10], [7,0]])\n","y = np.array([1,1,1,1,-1,-1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qPcFoZwoU2fp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Example 2: draw npos and nneg points from the Gaussian distribution for each class\n","npos = 30\n","nneg = 30\n","np.random.seed(321)\n","X = np.r_[np.random.randn(npos, 2) + [3, 3], np.random.randn(nneg, 2)]\n","# [1,1,...,1,-1,-1,...,-1]\n","y = np.array([1] * npos + [-1] * nneg)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IAcLs8fxU3b8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Example 3: create moons using sklearn\n","from sklearn.datasets import make_moons\n","X, y = make_moons(n_samples=100, noise=0.2, random_state=0)\n","y[y==0] = -1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"O5xj700RhOad","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Example 4: create circles using sklearn\n","from sklearn.datasets import make_circles\n","X, y = make_circles(n_samples=150, noise=0.1, random_state=0, factor=0.3)\n","y[y==0] = -1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tbqXssHcU5Is","colab_type":"text"},"cell_type":"markdown","source":["Plot the training points"]},{"metadata":{"id":"cl-028CoG9aE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Plot the training points\n","ax = plt.figure()\n","ax = plt.axes()\n","ax.scatter(X[y>0, 0], X[y>0, 1], c='r',  marker='s', cmap=plt.cm.bwr, edgecolors='k', label='Training data', alpha=1)\n","ax.scatter(X[y<=0, 0], X[y<=0, 1], c='b', marker='o', cmap=plt.cm.bwr, edgecolors='k', label='Training data', alpha=1)\n","plt.xlabel('x1', fontsize=16)\n","plt.ylabel('x2', fontsize=16)\n","plt.xticks(fontsize=16)\n","plt.yticks(fontsize=16)\n","plt.gca().set_aspect('equal')\n","ax.set_xlim(X[:,0].min()-0.5, X[:,0].max()+0.5)\n","ax.set_ylim(X[:,1].min()-0.5, X[:,1].max()+0.5)\n","plt.tight_layout()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pT0P8z26G9aT","colab_type":"text"},"cell_type":"markdown","source":["Run the training\n","----------------"]},{"metadata":{"id":"OA7s-t0MG9ae","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Gaussian Naive Bayes\n","from sklearn.naive_bayes import GaussianNB\n","\n","model = GaussianNB()\n","model.fit(X,y)\n","\n","#number of training samples observed in each class\n","print(\"# of data: \", model.class_count_)\n","\n","#probability of each class\n","print(\"Prior probs: \", model.class_prior_)\n","\n","#mean and variance of each feature per class\n","print(\"Mean: \", model.theta_)\n","print(\"Variance: \", model.sigma_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v0QWpXIs_ngb","colab_type":"text"},"cell_type":"markdown","source":["Visualize the Gaussian distributions\n","-----------------------------------------"]},{"metadata":{"id":"Pok0V1O2jk1v","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["dlim = np.sqrt(model.sigma_).sum(axis=0)/2\n","plot2d_GaussianNB(model, X, y, dxlim=dlim[0], dylim=dlim[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B0NGCvSX8mKw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Classification test\n","Xt = np.array([[16,6]])\n","print( N2d(Xt, model.theta_[0,:], model.sigma_[0,:]) )\n","print( N2d(Xt, model.theta_[1,:], model.sigma_[1,:]) )\n","print(\"Xt = \", \"is classified into \", model.predict(Xt), \"with probability\", np.max(model.predict_proba(Xt)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lUVP4jZM3i1y","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from google.colab import files\n","files.download(\"rnd2d_ex1_GNB.png\")"],"execution_count":0,"outputs":[]}]}